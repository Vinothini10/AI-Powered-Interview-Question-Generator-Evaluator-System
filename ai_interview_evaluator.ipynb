# AI-Powered Interview System – Modularised agents & orchestrator
# Input – Job description text file (job_description.txt).
# Input – Candidate answers text file (candidate_answers.txt).
# Process – Multi-agent system analyzes job description, generates interview questions, evaluates answers, and scores candidates.
# Decision Logic – Agent combines evaluation with rules to produce final recommendation (Hire / No-hire / Irrelevant).
# Output – Structured JSON per candidate + tabular summary with overall score, decision, strengths, and weaknesses.
# =========================================================================================================

import os
import json
import pandas as pd
from langchain.chat_models import AzureChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory

# Set Azure OpenAI credentials
os.environ["AZURE_OPENAI_API_VERSION"] = "2024-02-15-preview"


# Instantiate LLM
llm = AzureChatOpenAI(
    deployment_name="interview-llm",
    model_name="gpt-4",
    temperature=1,
    api_version="2024-02-15-preview"
)

# -----------------------------
# Modular Agents (Functions)
# -----------------------------

def analyze_job_description(job_description: str):
    jd_prompt = PromptTemplate(
        input_variables=["job_description"],
        template="""
        You are an expert recruiter. Extract key skills and responsibilities from this job description.
        Return a concise bullet list.

        Job Description:
        {job_description}
        """
    )
    jd_chain = LLMChain(
        llm=llm,
        prompt=jd_prompt,
        memory=ConversationBufferMemory(memory_key="jd_memory", return_messages=True)
    )
    return jd_chain.run(job_description)


def generate_interview_questions(role_summary: str):
    qgen_prompt = PromptTemplate(
        input_variables=["role_summary"],
        template="""
        You are an expert interviewer. Based on the following role summary, generate 5 structured interview questions.
        Return JSON list with fields: 'question' and 'type' (technical, behavioral, other).

        Role Summary:
        {role_summary}
        """
    )
    qgen_chain = LLMChain(
        llm=llm,
        prompt=qgen_prompt,
        memory=ConversationBufferMemory(memory_key="qgen_memory", return_messages=True)
    )
    questions_str = qgen_chain.run(role_summary)
    try:
        questions = json.loads(questions_str)
    except json.JSONDecodeError:
        questions = [{"question": questions_str, "type": "other"}]
    return questions


def evaluate_candidate_answers(questions_json: str, candidate_answers: str):
    eval_prompt = PromptTemplate(
        input_variables=["questions", "answers"],
        template= """You are a technical interviewer evaluating a candidate for a software engineering role.
Provide an assessment in JSON with:
- overall_score (1-5)
- technical_depth_score (1-5)
- system_design_score (1-5)
- cloud_and_ops_score (1-5)
- behavioral_score (1-5)
- summary

Questions:
{questions}

Candidate Answers:
{answers}
""" 
    )
    eval_chain = LLMChain(llm=llm, prompt=eval_prompt, verbose=False)
    return eval_chain.predict(questions=questions_json, answers=candidate_answers)


def generate_hiring_recommendation(eval_result: str):
    recommend_prompt = PromptTemplate(
        input_variables=["evaluation"], 
        template = """
You are a senior hiring manager reviewing a candidate evaluation.

Provide a final structured hiring recommendation.
Return JSON with:
- overall_score
- decision (Hire / No-hire / Irrelevant)
- strengths
- weaknesses
- rationale

Decision rules:
- overall_score >= 4 → Hire
- overall_score == 3 → No-hire
- overall_score <= 2 with unrelated experience → Irrelevant
- overall_score <= 2 with relevant experience → No-hire

Evaluation:
{evaluation}
"""    
    )
    recommend_chain = LLMChain(llm=llm, prompt=recommend_prompt, verbose=False)
    return recommend_chain.predict(evaluation=eval_result)


# -----------------------------
# Orchestrator
# -----------------------------
def run_interview_system(job_description: str, candidate_answers: str):
    role_summary = analyze_job_description(job_description)
    questions = generate_interview_questions(role_summary)
    questions_json = json.dumps(questions, indent=2)
    eval_result = evaluate_candidate_answers(questions_json, candidate_answers)
    final_recommendation = generate_hiring_recommendation(eval_result)

    return {
        "role_summary": role_summary,
        "questions": questions,
        "evaluation": eval_result,
        "final_recommendation": final_recommendation
    }

# -----------------------------
# File reading functions
# -----------------------------
def read_job_description(file_path="job_description.txt"):
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read().strip()


def read_candidates_from_file(file_path="candidate_answers.txt"):
    with open(file_path, "r") as f:
        content = f.read()
    candidates_raw = [c.strip() for c in content.split("# Candidate") if c.strip()]
    candidates = []
    for c in candidates_raw:
        lines = c.splitlines()
        label = "Candidate " + lines[0].strip()
        answers = "\n".join(lines[1:]).strip()
        candidates.append((label, answers))
    return candidates


# -----------------------------
# Main workflow
# -----------------------------
job_description = read_job_description("job_description.txt")
candidates = read_candidates_from_file("candidate_answers.txt")

results_table = []
# print(job_description)

for label, answers in candidates:
    result = run_interview_system(job_description, answers)
    final_rec = json.loads(result["final_recommendation"])
    results_table.append({
        "Candidate": label,
        "Overall Score": final_rec.get("overall_score"),
        "Decision": final_rec.get("decision"),
        "Strengths": ", ".join(final_rec.get("strengths", [])),
        "Weaknesses": ", ".join(final_rec.get("weaknesses", []))
    })

# Display results
df = pd.DataFrame(results_table)
display(df)
